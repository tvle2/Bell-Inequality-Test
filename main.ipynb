{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qutip import basis, ket2dm, tensor, expect, fidelity\n",
    "\n",
    "# Define the states\n",
    "H = basis(2,0)\n",
    "V = basis(2,1)\n",
    "\n",
    "## Maximally entangled EPR pairs:\n",
    "phi_plus = (tensor(H, H) + tensor(V, V)).unit()\n",
    "\n",
    "## Maximally entangled EPR pairs with mixture:\n",
    "rho = 0.7*ket2dm(phi_plus) + 0.15*ket2dm(tensor(H, V)) + 0.15*ket2dm(tensor(V, H))\n",
    "\n",
    "## Non-maximally entangled pair:\n",
    "phi = (1/np.sqrt(5)*tensor(H,H) + 2/np.sqrt(5)*tensor(V,V)).unit()\n",
    "\n",
    "\n",
    "## Non-maximally entangled pair with mixture:\n",
    "rho_prime = 0.7*ket2dm(phi) + 0.15*ket2dm(tensor(H, V)) + 0.15*ket2dm(tensor(V, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of photon generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_detection(rate, eff, dark_rate, dead_time, totol_time):\n",
    "    t, counts = 0, 0\n",
    "    dead = False\n",
    "    while t < totol_time:\n",
    "        if dead:\n",
    "            t+= dead_time\n",
    "            dead = False\n",
    "        else:  \n",
    "            photon_interval = np.random.exponential(1/rate)\n",
    "            dark_interval = np.random.exponential(1/dark_rate)\n",
    "            dt = min(photon_interval, dark_interval)\n",
    "            t += dt\n",
    "            if np.random.rand() < eff:\n",
    "                counts += 1\n",
    "                dead = True\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis selection and Bell measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# QuTiP for quantum objects, states, operators, and fidelity\n",
    "try:\n",
    "    from qutip import basis, ket2dm, tensor, fidelity, qeye\n",
    "except ImportError:\n",
    "    print(\"Please install QuTiP with: pip install qutip\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "###############################################################################\n",
    "# 1) Define the relevant quantum states\n",
    "###############################################################################\n",
    "# Basis vectors |H> and |V>\n",
    "H = basis(2, 0)\n",
    "V = basis(2, 1)\n",
    "\n",
    "# |Φ⁺> = 1/sqrt(2) (|HH> + |VV>)\n",
    "Phi_plus = (tensor(H, H) + tensor(V, V)).unit()\n",
    "\n",
    "# ρ = 0.7 |Φ⁺><Φ⁺| + 0.15 |HV><HV| + 0.15 |VH><VH|\n",
    "rho = 0.7 * ket2dm(Phi_plus) \\\n",
    "    + 0.15 * ket2dm(tensor(H, V)) \\\n",
    "    + 0.15 * ket2dm(tensor(V, H))\n",
    "\n",
    "# |φ> = 1/sqrt(5) |HH> + 2/sqrt(5) |VV>\n",
    "phi = (1/np.sqrt(5) * tensor(H, H) + 2/np.sqrt(5) * tensor(V, V)).unit()\n",
    "\n",
    "# ρ' = 0.7 |φ><φ| + 0.15 |HV><HV| + 0.15 |VH><VH|\n",
    "rho_prime = 0.7 * ket2dm(phi) \\\n",
    "    + 0.15 * ket2dm(tensor(H, V)) \\\n",
    "    + 0.15 * ket2dm(tensor(V, H))\n",
    "\n",
    "# Put them in a dictionary for easy iteration\n",
    "all_states = {\n",
    "    \"Phi_plus (pure)\": ket2dm(Phi_plus),\n",
    "    \"rho (mixed ME)\": rho,\n",
    "    \"phi (non-max pure)\": ket2dm(phi),\n",
    "    \"rho_prime (non-max mixed)\": rho_prime\n",
    "}\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) Simulation parameters\n",
    "###############################################################################\n",
    "# Average entangled-photon-pair generation rate (Poisson)\n",
    "ENTANGLEMENT_RATE = 15000  # pairs per second\n",
    "\n",
    "# Detector parameters\n",
    "DETECTOR_EFFICIENCY = 0.10    # 10%\n",
    "DARK_COUNT_RATE = 1000        # 1000 Hz\n",
    "DEAD_TIME = 4e-6              # 4 microseconds\n",
    "\n",
    "# Coincidence window\n",
    "COINCIDENCE_WINDOW = 1e-9     # 1 nanosecond\n",
    "\n",
    "# Total run time (seconds)\n",
    "TOTAL_TIME = 30\n",
    "\n",
    "# For reproducibility (remove or change seed as needed)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3) Simplified detection simulation\n",
    "###############################################################################\n",
    "def simulate_detection_and_timestamps(rate_source,\n",
    "                                      rate_dark,\n",
    "                                      eff_detector,\n",
    "                                      dead_time,\n",
    "                                      total_time):\n",
    "    \"\"\"\n",
    "    Simulate detection events (arrival times) over 'total_time'.\n",
    "\n",
    "    rate_source: Rate of \"true\" signal (photons or pairs).\n",
    "    rate_dark: Dark-count rate (counts/s).\n",
    "    eff_detector: Detector efficiency (fraction).\n",
    "    dead_time: No detection can occur during this time after a detection.\n",
    "    total_time: Simulation duration in seconds.\n",
    "\n",
    "    Returns: A sorted numpy array of detection timestamps (in seconds).\n",
    "    \"\"\"\n",
    "    # Use an event-driven approach:\n",
    "    # Generate times of \"true\" signal with Poisson process,\n",
    "    # plus times of dark counts with Poisson process,\n",
    "    # combine, sort, and enforce dead time.\n",
    "\n",
    "    # 1) Generate random times for actual photons\n",
    "    #    The number of photons in total_time ~ Poisson(rate_source * total_time).\n",
    "    n_source = np.random.poisson(rate_source * total_time)\n",
    "    #    Each arrival time is uniform in [0, total_time], or we can treat it\n",
    "    #    as an ordered Poisson process. For simplicity, we do uniform here:\n",
    "    source_times = np.random.rand(n_source) * total_time\n",
    "\n",
    "    # 2) Generate random times for dark counts\n",
    "    n_dark = np.random.poisson(rate_dark * total_time)\n",
    "    dark_times = np.random.rand(n_dark) * total_time\n",
    "\n",
    "    # 3) Combine and sort\n",
    "    all_times = np.concatenate((source_times, dark_times))\n",
    "    all_times.sort()\n",
    "\n",
    "    # 4) Probabilistic detection (efficiency)\n",
    "    #    We do a Bernoulli trial for each event to see if it is detected.\n",
    "    #    For \"true\" source events we also multiply by DETECTOR_EFFICIENCY;\n",
    "    #    for dark counts, they \"occur\" with certainty but we also do the same\n",
    "    #    detection pass? Many ways to handle it; here we treat them equally:\n",
    "    detect_mask = np.random.rand(len(all_times)) < eff_detector\n",
    "    detect_times = all_times[detect_mask]\n",
    "\n",
    "    # 5) Enforce dead time: after a detection, ignore subsequent events\n",
    "    #    that occur within 'dead_time'.\n",
    "    final_times = []\n",
    "    last_detection = -np.inf\n",
    "    for t in detect_times:\n",
    "        if t - last_detection >= dead_time:\n",
    "            final_times.append(t)\n",
    "            last_detection = t\n",
    "\n",
    "    return np.array(final_times)\n",
    "\n",
    "\n",
    "def count_coincidences(times_a, times_b, coincidence_window):\n",
    "    \"\"\"\n",
    "    Count how many pairs of detection times are within 'coincidence_window'.\n",
    "    A naive approach: for each detection time in 'times_a', we find any\n",
    "    detection times in 'times_b' that lie within +/- coincidence_window/2\n",
    "    (or just +/- window if we choose). For small arrays, a double loop works;\n",
    "    for large arrays, we can do better with a two-pointer approach.\n",
    "\n",
    "    Returns: The number of coincident pairs.\n",
    "    \"\"\"\n",
    "    # Two-pointer approach\n",
    "    i, j = 0, 0\n",
    "    n_coinc = 0\n",
    "    while i < len(times_a) and j < len(times_b):\n",
    "        dt = times_a[i] - times_b[j]\n",
    "        if abs(dt) <= coincidence_window:\n",
    "            # We have a coincidence\n",
    "            n_coinc += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif dt > 0:\n",
    "            # times_b[j] is behind times_a[i], move b forward\n",
    "            j += 1\n",
    "        else:\n",
    "            # times_a[i] is behind times_b[j], move a forward\n",
    "            i += 1\n",
    "    return n_coinc\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4) Bell measurement & CHSH S-parameter\n",
    "###############################################################################\n",
    "def projector(theta):\n",
    "    \"\"\"\n",
    "    Projector onto the state:\n",
    "        cos(theta)|H> + sin(theta)|V>\n",
    "    Returns a rank-1 projector in QuTiP representation (2x2).\n",
    "    \"\"\"\n",
    "    # state vector in the single-qubit space\n",
    "    state = np.cos(theta) * H + np.sin(theta) * V\n",
    "    return ket2dm(state.unit())\n",
    "\n",
    "\n",
    "def compute_chsh_s(rho_2qubit):\n",
    "    \"\"\"\n",
    "    Compute the CHSH S-value for the 2-qubit state 'rho_2qubit'\n",
    "    using the typical measurement angles:\n",
    "        A = 0°, A' = 45°,\n",
    "        B = 22.5°, B' = 67.5°.\n",
    "\n",
    "    S = E(A,B) - E(A,B') + E(A',B) + E(A',B'),\n",
    "    where E(...) is the expectation of the correlation (±1 outcomes).\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians\n",
    "    a = 0.0 * np.pi/180\n",
    "    ap = 45.0 * np.pi/180\n",
    "    b = 22.5 * np.pi/180\n",
    "    bp = 67.5 * np.pi/180\n",
    "\n",
    "    # For a single angle θ, we define projector P(θ).\n",
    "    # The \"observable\" for spin-like correlation is:\n",
    "    #     O(θ) = P(θ) - P(θ+π/2)\n",
    "    # In polarization language, measuring \"H/V\" ~ (0°, 90°),\n",
    "    # or \"D/A\" ~ (45°, 135°), etc.\n",
    "    #\n",
    "    # A more direct approach for CHSH:\n",
    "    # E(a, b) = Pr(++|ab) + Pr(--|ab) - Pr(+-|ab) - Pr(-+|ab)\n",
    "    #\n",
    "    # We'll do a short routine to compute E(...) for given angles a, b.\n",
    "    return (\n",
    "        E_ab(rho_2qubit, a, b)\n",
    "        - E_ab(rho_2qubit, a, bp)\n",
    "        + E_ab(rho_2qubit, ap, b)\n",
    "        + E_ab(rho_2qubit, ap, bp)\n",
    "    )\n",
    "\n",
    "\n",
    "def E_ab(rho_2qubit, theta_a, theta_b):\n",
    "    \"\"\"\n",
    "    Compute E(a, b) = Probability(++ or --) - Probability(+- or -+),\n",
    "    measuring single-qubit angles theta_a and theta_b on qubit A and B.\n",
    "    \"\"\"\n",
    "    # Define rank-1 projectors for the + outcome:\n",
    "    P_plus_A = projector(theta_a)\n",
    "    P_plus_B = projector(theta_b)\n",
    "\n",
    "    # The complementary projectors (for the - outcome) are:\n",
    "    P_minus_A = (qeye(2) - P_plus_A)\n",
    "    P_minus_B = (qeye(2) - P_plus_B)\n",
    "\n",
    "    # Probability of + + is  <P_plus_A \\otimes P_plus_B>\n",
    "    pp = (P_plus_A.tensor(P_plus_B) * rho_2qubit).tr()\n",
    "    # Probability of - - is <P_minus_A \\otimes P_minus_B>\n",
    "    mm = (P_minus_A.tensor(P_minus_B) * rho_2qubit).tr()\n",
    "    # Probability of + - is <P_plus_A \\otimes P_minus_B>\n",
    "    pm = (P_plus_A.tensor(P_minus_B) * rho_2qubit).tr()\n",
    "    # Probability of - + is <P_minus_A \\otimes P_plus_B>\n",
    "    mp = (P_minus_A.tensor(P_plus_B) * rho_2qubit).tr()\n",
    "\n",
    "    return (pp + mm) - (pm + mp)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5) Putting it all together\n",
    "###############################################################################\n",
    "def run_simulation_for_state(state_name, rho_2qubit):\n",
    "    \"\"\"\n",
    "    1. Generate detection timestamps for Alice and Bob.\n",
    "    2. Count total detection rate, coincidence rate.\n",
    "    3. Compute fidelity with ideal |Φ+>.\n",
    "    4. Compute Bell S parameter.\n",
    "    \"\"\"\n",
    "    # 1) Simulate detection event times for Alice and Bob\n",
    "    alice_times = simulate_detection_and_timestamps(\n",
    "        rate_source=ENTANGLEMENT_RATE,    # For her half of the pairs\n",
    "        rate_dark=DARK_COUNT_RATE,\n",
    "        eff_detector=DETECTOR_EFFICIENCY,\n",
    "        dead_time=DEAD_TIME,\n",
    "        total_time=TOTAL_TIME\n",
    "    )\n",
    "    bob_times = simulate_detection_and_timestamps(\n",
    "        rate_source=ENTANGLEMENT_RATE,    # For Bob's half\n",
    "        rate_dark=DARK_COUNT_RATE,\n",
    "        eff_detector=DETECTOR_EFFICIENCY,\n",
    "        dead_time=DEAD_TIME,\n",
    "        total_time=TOTAL_TIME\n",
    "    )\n",
    "\n",
    "    total_count_rate_alice = len(alice_times) / TOTAL_TIME\n",
    "    total_count_rate_bob   = len(bob_times)   / TOTAL_TIME\n",
    "\n",
    "    # 2) Count coincidences (very simplified),\n",
    "    #    ignoring which measurement basis was used, just a raw coincidence.\n",
    "    n_coinc = count_coincidences(alice_times, bob_times, COINCIDENCE_WINDOW)\n",
    "    coincidence_rate = n_coinc / TOTAL_TIME\n",
    "\n",
    "    # 3) Fidelity with |Φ+>\n",
    "    #    QuTiP has a direct fidelity function:\n",
    "    F = fidelity(rho_2qubit, ket2dm(Phi_plus))\n",
    "\n",
    "    # 4) Bell S value from the CHSH scenario:\n",
    "    #    We do a purely \"state-based\" CHSH calculation here, ignoring\n",
    "    #    the detection inefficiencies, for demonstration.\n",
    "    S = compute_chsh_s(rho_2qubit)\n",
    "\n",
    "    print(f\"=== Results for state: {state_name} ===\")\n",
    "    print(f\"  Total Count Rate (Alice)  = {total_count_rate_alice:.2f} counts/s\")\n",
    "    print(f\"  Total Count Rate (Bob)    = {total_count_rate_bob:.2f} counts/s\")\n",
    "    print(f\"  Coincidence Rate         = {coincidence_rate:.2f} counts/s\")\n",
    "    print(f\"  Fidelity w.r.t. |Phi+>   = {F:.3f}\")\n",
    "    print(f\"  Bell S value (CHSH)      = {S:.3f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main driver: loop over the four states and run the simulation + analytics.\n",
    "    \"\"\"\n",
    "    for name, state in all_states.items():\n",
    "        run_simulation_for_state(name, state)\n",
    "\n",
    "    # Optional: If you want a quick demonstration or comparison plot\n",
    "    # of S vs. p in a Werner state, you could do something like:\n",
    "    # (CSC 791 extension: Searching for minimal S > 2 that still violates.)\n",
    "    # Uncomment if desired.\n",
    "\n",
    "    import qutip\n",
    "    p_vals = np.linspace(0.0, 1.0, 21)\n",
    "    s_vals = []\n",
    "    for p in p_vals:\n",
    "        # Werner state: rho_W = p|Phi+><Phi+| + (1-p)I/4\n",
    "        rho_W = p * ket2dm(Phi_plus) + (1 - p) * (qeye(4) / 4)\n",
    "        s_vals.append(compute_chsh_s(rho_W))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(p_vals, s_vals, marker='o')\n",
    "    plt.xlabel(\"p (Werner state parameter)\")\n",
    "    plt.ylabel(\"CHSH S-value\")\n",
    "    plt.title(\"Werner State CHSH S vs. p\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
